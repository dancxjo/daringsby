use anyhow::Result;
use async_trait::async_trait;
use std::pin::Pin;
use tokio_stream::Stream;

/// Trait for executing imperative instructions (e.g., take a photo, run a Cypher query).
///
/// Used by the `Will` to invoke external side effects or decisions via LLM-generated
/// commands.
///
/// ## Example
/// ```rust,ignore
/// let output = doer.follow("take a photo").await?;
/// println!("Output: {output}");
/// ```
#[async_trait]
pub trait Doer: Send + Sync {
    /// Execute the given instruction and return the textual result.
    ///
    /// Implementors may call an external LLM or other service.
    async fn follow(&self, instruction: &str) -> Result<String>;
}

/// Indicates the speaker of a message in a conversation.
///
/// `Role::User` = input from outside world.
/// `Role::Assistant` = output generated by Pete (via `Voice`).
#[derive(Clone, Debug, PartialEq, Eq)]
pub enum Role {
    Assistant,
    User,
}

/// Represents a single utterance in a chat history.
///
/// Used to maintain prompt history when calling the [`Chatter`] trait.
#[derive(Clone, Debug)]
pub struct Message {
    pub role: Role,
    pub content: String,
}

impl Message {
    /// Create a new user message.
    pub fn user(content: impl Into<String>) -> Self {
        Self {
            role: Role::User,
            content: content.into(),
        }
    }

    /// Create a new assistant message.
    pub fn assistant(content: impl Into<String>) -> Self {
        Self {
            role: Role::Assistant,
            content: content.into(),
        }
    }
}

/// An asynchronous stream of `Result<String>` response chunks from the LLM.
///
/// Used by [`Chatter::chat`]. Typically emits partial sentences or word
/// fragments. Terminates when the full response has been streamed.
pub type ChatStream = Pin<Box<dyn Stream<Item = Result<String>> + Send>>;

/// Trait for conversational generation. Produces a stream of natural language chunks.
///
/// This is used **exclusively** by the `Voice` Wit to generate speech content.
/// It receives a system prompt and conversation history, and returns a stream of
/// partial strings.
///
/// The returned [`ChatStream`] emits chunks progressively, enabling real-time
/// speech synthesis.
///
/// ## Example
/// ```rust,ignore
/// let stream = chatter.chat("You are Pete", &[Message::user("Hi")]).await?;
/// tokio::pin!(stream);
/// while let Some(chunk) = stream.next().await {
///     println!("LLM: {}", chunk?);
/// }
/// ```
#[async_trait]
pub trait Chatter: Send + Sync {
    /// Start a chat session using `system_prompt` and `history`.
    ///
    /// Returns a stream of response chunks from the language model.
    async fn chat(&self, system_prompt: &str, history: &[Message]) -> Result<ChatStream>;
}

/// Trait for generating semantic vector embeddings from text.
///
/// Used for memory indexing into Qdrant. The input text should be one complete
/// sentence representing an [`Impression`] headline.
#[async_trait]
pub trait Vectorizer: Send + Sync {
    /// Convert `text` into a vector representation suitable for similarity search.
    async fn vectorize(&self, text: &str) -> Result<Vec<f32>>;
}
