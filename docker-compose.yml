services:
  nginx:
    image: nginx:latest
    container_name: nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./certs:/etc/nginx/certs:ro
      - /etc/timezone:/etc/timezone:ro
    depends_on:
      - deno_project

  deno_project:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: deno_project
    volumes:
      - .:/app
      - ./certs:/app/certs
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    ports:
      - "8000:8000"
    environment:
      - TZ=America/Los_Angeles
      - PERCEPTION_OLLAMA_URL=http://forebrain.local:11434
      - COMPREHENSION_OLLAMA_URL=http://forebrain.local:11434
      - OLLAMA_URL=http://forebrain.local:11434
      - OLLAMA2_URL=http://10.0.0.95:11434
      - COQUI_URL=http://tts:5002
      - WHISPER_URL=http://whisper:9000
      - NEO4J_URL=bolt://neo4j:7687
      - QDRANT_URL=http://qdrant:6333
      - OLLAMA_MODEL=llama3
      - OLLAMA2_MODEL=gemma2:27b
      - SPEAKER=Royston Min
    depends_on:
      - neo4j
      - tts
      - whisper
      - qdrant

  neo4j:
    image: neo4j:latest
    container_name: neo4j
    environment:
      NEO4J_AUTH: neo4j/password
    ports:
      - "7474:7474"
      - "7687:7687"
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
      - neo4j_import:/var/lib/neo4j/import
      - neo4j_plugins:/plugins
      - /etc/timezone:/etc/timezone:ro

  tts:
    image: ghcr.io/coqui-ai/tts
    ports:
      - 5002:5002
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - VOCODER_MODEL="vocoder_models/en/ljspeech/hifigan_v1"
      - COQUI_TOS_AGREED=1
      - TTS_MODEL="tts_models/en/ljspeech/tacotron2-DDC"
    entrypoint: python3
    command: ["TTS/server/server.py", "--model_name", "tts_models/en/vctk/vits"]
    runtime: nvidia
    volumes:
      - ./tts:/root/.local/share
      - /etc/timezone:/etc/timezone:ro
    deploy:
      resources:
        reservations:
          devices:
            - count: all
              capabilities: [gpu]

  whisper:
    image: onerahmet/openai-whisper-asr-webservice:latest-gpu
    runtime: nvidia
    ports:
      - "9000:9000"
    environment:
      - ASR_MODEL=base
    restart: always

  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_data:/qdrant/storage
      - /etc/timezone:/etc/timezone:ro

  compreface-postgres-db:
    image: exadel/compreface-postgres-db:${POSTGRES_VERSION}
    restart: always
    container_name: "compreface-postgres-db"
    environment:
      - POSTGRES_USER=${postgres_username}
      - POSTGRES_PASSWORD=${postgres_password}
      - POSTGRES_DB=${postgres_db}
    volumes:
      - postgres-data:/var/lib/postgresql/data

  compreface-admin:
    restart: always
    image: exadel/compreface-admin:${ADMIN_VERSION}
    container_name: "compreface-admin"
    environment:
      - POSTGRES_USER=${postgres_username}
      - POSTGRES_PASSWORD=${postgres_password}
      - POSTGRES_URL=jdbc:postgresql://${postgres_domain}:${postgres_port}/${postgres_db}
      - SPRING_PROFILES_ACTIVE=dev
      - ENABLE_EMAIL_SERVER=${enable_email_server}
      - EMAIL_HOST=${email_host}
      - EMAIL_USERNAME=${email_username}
      - EMAIL_FROM=${email_from}
      - EMAIL_PASSWORD=${email_password}
      - ADMIN_JAVA_OPTS=${compreface_admin_java_options}
      - MAX_FILE_SIZE=${max_file_size}
      - MAX_REQUEST_SIZE=${max_request_size}B
    depends_on:
      - compreface-postgres-db
      - compreface-api

  compreface-api:
    restart: always
    image: exadel/compreface-api:${API_VERSION}
    container_name: "compreface-api"
    depends_on:
      - compreface-postgres-db
    environment:
      - POSTGRES_USER=${postgres_username}
      - POSTGRES_PASSWORD=${postgres_password}
      - POSTGRES_URL=jdbc:postgresql://${postgres_domain}:${postgres_port}/${postgres_db}
      - SPRING_PROFILES_ACTIVE=dev
      - API_JAVA_OPTS=${compreface_api_java_options}
      - SAVE_IMAGES_TO_DB=${save_images_to_db}
      - MAX_FILE_SIZE=${max_file_size}
      - MAX_REQUEST_SIZE=${max_request_size}B
      - CONNECTION_TIMEOUT=${connection_timeout:-10000}
      - READ_TIMEOUT=${read_timeout:-60000}

  compreface-fe:
    restart: always
    image: exadel/compreface-fe:${FE_VERSION}
    container_name: "compreface-ui"
    ports:
      - "8008:80"
    depends_on:
      - compreface-api
      - compreface-admin
    environment:
      - CLIENT_MAX_BODY_SIZE=${max_request_size}
      - PROXY_READ_TIMEOUT=${read_timeout:-60000}ms
      - PROXY_CONNECT_TIMEOUT=${connection_timeout:-10000}ms

  compreface-core:
    restart: always
    image: exadel/compreface-core:${CORE_VERSION}
    container_name: "compreface-core"
    environment:
      - ML_PORT=3000
      - IMG_LENGTH_LIMIT=${max_detect_size}
      - UWSGI_PROCESSES=${uwsgi_processes:-2}
      - UWSGI_THREADS=${uwsgi_threads:-1}
    healthcheck:
      test: curl --fail http://localhost:3000/healthcheck || exit 1
      interval: 10s
      retries: 0
      start_period: 0s
      timeout: 1s
      
volumes:
  neo4j_data:
  neo4j_logs:
  neo4j_import:
  neo4j_plugins:
  ollama:
  letsencrypt:
  qdrant_data:
  postgres-data:
